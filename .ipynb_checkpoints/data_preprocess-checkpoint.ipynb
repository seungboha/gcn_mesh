{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vtk(filename):\n",
    "    fid = open(filename, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "\n",
    "    v = []\n",
    "    f = []\n",
    "    b = ([lines.index(i) for i in lines if i.startswith(\"POINTS\")])[0] + 1\n",
    "    nVert = int(lines[b - 1].split()[1])\n",
    "    for i in range(b, b + nVert):\n",
    "        line = lines[i]\n",
    "        row = [float(n) for n in line.split()] \n",
    "        v.append(row)\n",
    "\n",
    "    b = ([lines.index(i) for i in lines if i.startswith(\"POLYGONS\")])[0] + 1 \n",
    "    nFaces = int(lines[b - 1].split()[1])\n",
    "    for i in range(b, b + nFaces):\n",
    "        line = lines[i]\n",
    "        row = [int(n) for n in line.split()]\n",
    "        row = row[1:]\n",
    "        f.append(row)\n",
    "\n",
    "    v = np.array(v)\n",
    "    f = np.array(f)\n",
    "    return v, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/MMRR-21-20/'\n",
    "features = []\n",
    "for file in glob.glob(os.path.join(path, \"lh.*.txt\")):\n",
    "    feat = np.genfromtxt(file, dtype=np.float32)\n",
    "    features.append(feat)\n",
    "features = np.array(features)\n",
    "features = np.transpose(features)\n",
    "#features = sp.csr_matrix(features)\n",
    "\n",
    "labels_path = os.path.join(path, \"label\")\n",
    "labels_data = np.genfromtxt(os.path.join(labels_path, \"lh.label.txt\"))\n",
    "labels = encode_onehot(labels_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v, f] = read_vtk(os.path.join(path, 'lh.white.vtk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_edges = np.concatenate(\n",
    "    [np.stack((f[:, 0], f[:, 1]), axis=1),\n",
    "        np.stack((f[:, 1], f[:, 2]), axis=1),\n",
    "        np.stack((f[:, 2], f[:, 0]), axis=1)],\n",
    "    axis=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.coo_matrix(\n",
    "    (np.ones(unordered_edges.shape[0]), (unordered_edges[:, 0], unordered_edges[:, 1])),    # row, col\n",
    "    shape=(labels.shape[0], labels.shape[0]),\n",
    "    dtype=np.float32\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsum = np.array(features.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_inv = np.power(colsum, -1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_inv[np.isinf(c_inv)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mat_inv = sp.diags(c_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_mat_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"\n",
    "    Col-normalize sparse matrix\n",
    "    Variance of sparse matrix a\n",
    "    var = mean(a**2) - mean(a)**2\n",
    "    \"\"\"\n",
    "    mx_squared = mx.copy()\n",
    "    mx_squared.data **= 2\n",
    "    var = mx_squared.mean(axis=0) - np.square(mx.mean(axis=0))\n",
    "    std = np.sqrt(var)\n",
    "    mean = np.mean(mx, axis=0)\n",
    "    return (mx-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 149927)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(adj_squared.mean(axis=0) - np.square(adj.mean(axis=0))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = f\n",
    "unordered_edges = np.concatenate(\n",
    "    [np.stack((faces[:, 0], faces[:, 1]), axis=1), \n",
    "     np.stack((faces[:, 1], faces[:, 2]), axis=1),\n",
    "     np.stack((faces[:, 2], faces[:, 0]), axis=1)],\n",
    "    axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_edges[:, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.coo_matrix((np.ones(unordered_edges.shape[0]), \n",
    "                     (unordered_edges[:, 0], unordered_edges[:, 1])),    # row, col\n",
    "                    shape=(labels.shape[0], labels.shape[0]),\n",
    "                    dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_nodes = labels.shape[0]\n",
    "all_indices = np.arange(n_nodes)\n",
    "idx_test = random.sample(set(all_indices), int(n_nodes*0.2))\n",
    "idx_train_val = list(set(all_indices)-set(idx_test))\n",
    "idx_val = random.sample(set(idx_train_val), int(n_nodes*0.1))\n",
    "idx_train = list(set(idx_train_val) - set(idx_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(idx_train), len(idx_train))\n",
    "print(type(idx_test), len(idx_test))\n",
    "print(type(idx_val), len(idx_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idx_train) + len(idx_test) + len(idx_val) == n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's read meshes of all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/data/human/Mindboggle/DL/mesh/\"\n",
    "all_subjects = [subject for subject in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, subject))]\n",
    "n_subjects = len(all_subjects)\n",
    "print(n_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_test = random.sample(all_subjects, int(n_subjects*0.2))\n",
    "subj_tv = list(set(all_subjects) - set(subj_test))\n",
    "subj_train = random.sample(subj_tv, int(n_subjects*0.7))\n",
    "sub_val = list(set(subj_tv) - set(subj_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 81 11 70\n"
     ]
    }
   ],
   "source": [
    "print(len(subj_test), len(subj_tv), len(sub_val), len(subj_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    subj_train = random.sample(subj_tv, int(n_subjects*0.7))\n",
    "    sub_val = list(set(subj_tv) - set(subj_train))\n",
    "    \n",
    "    \n",
    "    # load data for each subject\n",
    "        # run model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"/data/human/Mindboggle/DL/label/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lh.white.vtk',\n",
       " 'lh.sphere.vtk',\n",
       " 'rh.white.vtk',\n",
       " 'rh.sphere.vtk',\n",
       " 'lh.curv.txt',\n",
       " 'lh.sulc.txt',\n",
       " 'lh.iH.txt',\n",
       " 'rh.curv.txt',\n",
       " 'rh.sulc.txt',\n",
       " 'rh.iH.txt',\n",
       " 'lh.thickness.txt',\n",
       " 'rh.thickness.txt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/data/human/Mindboggle/DL/mesh/Afterthought-1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name = ['curv', 'iH', 'sulc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curv\n",
      "<class 'numpy.ndarray'>\n",
      "iH\n",
      "<class 'numpy.ndarray'>\n",
      "sulc\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data/human/Mindboggle/DL/'\n",
    "mesh_path = os.path.join(data_path, \"mesh\")\n",
    "subject = 'Afterthought-1'\n",
    "subj_path = os.path.join(mesh_path, subject)\n",
    "[v, f] = read_vtk(os.path.join(subj_path, 'lh.white.vtk'))    # Index for vertices starts from 0\n",
    "\n",
    "features = []\n",
    "for name in feat_name:\n",
    "    print(name)\n",
    "    for file in glob.glob(os.path.join(subj_path, \"lh.{}.txt\".format(name))):\n",
    "        feat = np.genfromtxt(file, dtype=np.float32)\n",
    "        print(type(feat))\n",
    "        features.append(feat)\n",
    "features = np.array(features)\n",
    "features = np.transpose(features)\n",
    "features = sp.csr_matrix(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130921, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
